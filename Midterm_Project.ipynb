{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    " - We aim to fit a proper model for determining a subject's risk at coronary heart disease in last 10 years (`TenYearCHD`= 1 for YES, and 0 for NO).\n",
    " - We will apply feature selection methods such as principal component analysis (PCA), LASSO and elastic net to the logistic regression.\n",
    "        (1) For PCA: we determine the principal components(PCs) and regard these PCs as the dependent variables in the logistic regression.\n",
    "        (2) For LASSO: we use L1 regularization technique on the logistic regression.\n",
    "        (3) For elastic net: we use both L1 and L2 regularization technique on the logistic regression.\n",
    " - In addition to PCA and regularization technique, we conduct KMeans and Support Vector Machine (SVM) in order to classify the target variable `TenYearCHD`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data resource\n",
    "[Framingham Heart Decease Dataset](https://www.kaggle.com/amanajmera1/framingham-heart-study-dataset)\n",
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/framingham.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   male  age  education  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n",
       "0     1   39        4.0              0         0.0     0.0                0   \n",
       "1     0   46        2.0              0         0.0     0.0                0   \n",
       "2     1   48        1.0              1        20.0     0.0                0   \n",
       "3     0   61        3.0              1        30.0     0.0                0   \n",
       "4     0   46        3.0              1        23.0     0.0                0   \n",
       "\n",
       "   prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  \\\n",
       "0             0         0    195.0  106.0   70.0  26.97       80.0     77.0   \n",
       "1             0         0    250.0  121.0   81.0  28.73       95.0     76.0   \n",
       "2             0         0    245.0  127.5   80.0  25.34       75.0     70.0   \n",
       "3             1         0    225.0  150.0   95.0  28.58       65.0    103.0   \n",
       "4             0         0    285.0  130.0   84.0  23.10       85.0     85.0   \n",
       "\n",
       "   TenYearCHD  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           1  \n",
       "4           0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['male', 'age', 'education', 'currentSmoker', 'cigsPerDay', 'BPMeds',\n",
       "       'prevalentStroke', 'prevalentHyp', 'diabetes', 'totChol', 'sysBP',\n",
       "       'diaBP', 'BMI', 'heartRate', 'glucose', 'TenYearCHD'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data proprocessing: remove missing values\n",
    "First of all, we check whether there're missing values in each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male               False\n",
       "age                False\n",
       "education           True\n",
       "currentSmoker      False\n",
       "cigsPerDay          True\n",
       "BPMeds              True\n",
       "prevalentStroke    False\n",
       "prevalentHyp       False\n",
       "diabetes           False\n",
       "totChol             True\n",
       "sysBP              False\n",
       "diaBP              False\n",
       "BMI                 True\n",
       "heartRate           True\n",
       "glucose             True\n",
       "TenYearCHD         False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male               False\n",
       "age                False\n",
       "education          False\n",
       "currentSmoker      False\n",
       "cigsPerDay         False\n",
       "BPMeds             False\n",
       "prevalentStroke    False\n",
       "prevalentHyp       False\n",
       "diabetes           False\n",
       "totChol            False\n",
       "sysBP              False\n",
       "diaBP              False\n",
       "BMI                False\n",
       "heartRate          False\n",
       "glucose            False\n",
       "TenYearCHD         False\n",
       "full_cnt           False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['full_cnt'] = df.apply(lambda x: x.count(), axis=1) \n",
    "df_cdh = df[(df['full_cnt'] == 16)] # pick up rows with full values\n",
    "df_cdh.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = df_cdh.drop(['TenYearCHD','full_cnt'], axis=1)\n",
    "df_y = df_cdh['TenYearCHD']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data for 70% train and 30% test samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal component analysis (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We denote *PC* as a principal component. Assume that we find $k$ principal components, each of them is composed by the linear combination of the standardized $X_{i}$ ($Z_{i}$).\n",
    "$$PC_j=\\sum_{j=1}^{k}\\sum_{i=1}^{15}a_{i,j}Z_{i}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardizing the original features\n",
    "x_train_sd = StandardScaler().fit_transform(x_train.values)\n",
    "x_test_sd = StandardScaler().fit_transform(x_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.880518</td>\n",
       "      <td>-0.875261</td>\n",
       "      <td>0.021795</td>\n",
       "      <td>1.033369</td>\n",
       "      <td>-0.576079</td>\n",
       "      <td>-0.18532</td>\n",
       "      <td>-0.086472</td>\n",
       "      <td>-0.671749</td>\n",
       "      <td>-0.17253</td>\n",
       "      <td>-0.140265</td>\n",
       "      <td>-0.381025</td>\n",
       "      <td>-0.247836</td>\n",
       "      <td>-0.210725</td>\n",
       "      <td>1.176891</td>\n",
       "      <td>-0.204725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.880518</td>\n",
       "      <td>-1.580613</td>\n",
       "      <td>-0.957072</td>\n",
       "      <td>1.033369</td>\n",
       "      <td>-0.323060</td>\n",
       "      <td>-0.18532</td>\n",
       "      <td>-0.086472</td>\n",
       "      <td>1.488651</td>\n",
       "      <td>-0.17253</td>\n",
       "      <td>-0.322550</td>\n",
       "      <td>0.660732</td>\n",
       "      <td>0.928335</td>\n",
       "      <td>0.259853</td>\n",
       "      <td>0.026575</td>\n",
       "      <td>-0.450223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.880518</td>\n",
       "      <td>0.653001</td>\n",
       "      <td>-0.957072</td>\n",
       "      <td>-0.967709</td>\n",
       "      <td>-0.744758</td>\n",
       "      <td>-0.18532</td>\n",
       "      <td>-0.086472</td>\n",
       "      <td>-0.671749</td>\n",
       "      <td>-0.17253</td>\n",
       "      <td>0.315448</td>\n",
       "      <td>-0.018675</td>\n",
       "      <td>0.424262</td>\n",
       "      <td>-0.762185</td>\n",
       "      <td>0.190906</td>\n",
       "      <td>-0.491139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.880518</td>\n",
       "      <td>1.240795</td>\n",
       "      <td>0.021795</td>\n",
       "      <td>1.033369</td>\n",
       "      <td>0.942033</td>\n",
       "      <td>-0.18532</td>\n",
       "      <td>-0.086472</td>\n",
       "      <td>-0.671749</td>\n",
       "      <td>-0.17253</td>\n",
       "      <td>0.543304</td>\n",
       "      <td>0.298382</td>\n",
       "      <td>-0.163824</td>\n",
       "      <td>-0.257293</td>\n",
       "      <td>-0.137755</td>\n",
       "      <td>-0.491139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.135695</td>\n",
       "      <td>-1.580613</td>\n",
       "      <td>1.979529</td>\n",
       "      <td>-0.967709</td>\n",
       "      <td>-0.744758</td>\n",
       "      <td>-0.18532</td>\n",
       "      <td>-0.086472</td>\n",
       "      <td>-0.671749</td>\n",
       "      <td>-0.17253</td>\n",
       "      <td>-0.595978</td>\n",
       "      <td>-0.924551</td>\n",
       "      <td>0.214231</td>\n",
       "      <td>-0.931299</td>\n",
       "      <td>-0.384252</td>\n",
       "      <td>-0.204725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       male       age  education  currentSmoker  cigsPerDay   BPMeds  \\\n",
       "0 -0.880518 -0.875261   0.021795       1.033369   -0.576079 -0.18532   \n",
       "1 -0.880518 -1.580613  -0.957072       1.033369   -0.323060 -0.18532   \n",
       "2 -0.880518  0.653001  -0.957072      -0.967709   -0.744758 -0.18532   \n",
       "3 -0.880518  1.240795   0.021795       1.033369    0.942033 -0.18532   \n",
       "4  1.135695 -1.580613   1.979529      -0.967709   -0.744758 -0.18532   \n",
       "\n",
       "   prevalentStroke  prevalentHyp  diabetes   totChol     sysBP     diaBP  \\\n",
       "0        -0.086472     -0.671749  -0.17253 -0.140265 -0.381025 -0.247836   \n",
       "1        -0.086472      1.488651  -0.17253 -0.322550  0.660732  0.928335   \n",
       "2        -0.086472     -0.671749  -0.17253  0.315448 -0.018675  0.424262   \n",
       "3        -0.086472     -0.671749  -0.17253  0.543304  0.298382 -0.163824   \n",
       "4        -0.086472     -0.671749  -0.17253 -0.595978 -0.924551  0.214231   \n",
       "\n",
       "        BMI  heartRate   glucose  \n",
       "0 -0.210725   1.176891 -0.204725  \n",
       "1  0.259853   0.026575 -0.450223  \n",
       "2 -0.762185   0.190906 -0.491139  \n",
       "3 -0.257293  -0.137755 -0.491139  \n",
       "4 -0.931299  -0.384252 -0.204725  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data = x_train_sd, columns = x_train.columns).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=0.9, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(0.9)  # we want 90% of the information is attributed by principal components\n",
    "pca.fit(x_train_sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.n_components_ # number of principal components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we take a look at the ratios of explained variance, which state that how much information (variance) can be accounted by each of the principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.217, 0.128, 0.102, 0.075, 0.07 , 0.069, 0.067, 0.058, 0.052,\n",
       "       0.047, 0.038])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(pca.explained_variance_ratio_,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.923"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(sum(pca.explained_variance_ratio_),3) \n",
    "# 92.3% of the information is attributed by principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pc1</th>\n",
       "      <th>pc2</th>\n",
       "      <th>pc3</th>\n",
       "      <th>pc4</th>\n",
       "      <th>pc5</th>\n",
       "      <th>pc6</th>\n",
       "      <th>pc7</th>\n",
       "      <th>pc8</th>\n",
       "      <th>pc9</th>\n",
       "      <th>pc10</th>\n",
       "      <th>pc11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.938280</td>\n",
       "      <td>-0.019774</td>\n",
       "      <td>-0.016178</td>\n",
       "      <td>-1.547015</td>\n",
       "      <td>0.320923</td>\n",
       "      <td>-0.122549</td>\n",
       "      <td>0.651331</td>\n",
       "      <td>0.238001</td>\n",
       "      <td>0.332116</td>\n",
       "      <td>-0.134682</td>\n",
       "      <td>-0.135853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.760479</td>\n",
       "      <td>0.829974</td>\n",
       "      <td>-0.825928</td>\n",
       "      <td>-0.914624</td>\n",
       "      <td>-0.217050</td>\n",
       "      <td>-0.752348</td>\n",
       "      <td>1.173505</td>\n",
       "      <td>-0.570348</td>\n",
       "      <td>-0.056062</td>\n",
       "      <td>-1.416116</td>\n",
       "      <td>0.940763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.202428</td>\n",
       "      <td>-1.428618</td>\n",
       "      <td>-0.628125</td>\n",
       "      <td>-0.646743</td>\n",
       "      <td>-0.383793</td>\n",
       "      <td>0.902968</td>\n",
       "      <td>0.186972</td>\n",
       "      <td>-0.307763</td>\n",
       "      <td>-0.360890</td>\n",
       "      <td>0.209880</td>\n",
       "      <td>0.405470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.267417</td>\n",
       "      <td>0.668644</td>\n",
       "      <td>-0.262321</td>\n",
       "      <td>-0.454233</td>\n",
       "      <td>0.151922</td>\n",
       "      <td>1.486881</td>\n",
       "      <td>-0.561270</td>\n",
       "      <td>-0.170430</td>\n",
       "      <td>-0.441784</td>\n",
       "      <td>-0.619568</td>\n",
       "      <td>-1.010428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.646330</td>\n",
       "      <td>-0.700462</td>\n",
       "      <td>-0.152781</td>\n",
       "      <td>0.696984</td>\n",
       "      <td>1.038738</td>\n",
       "      <td>-2.052524</td>\n",
       "      <td>-0.711680</td>\n",
       "      <td>0.680242</td>\n",
       "      <td>-0.076988</td>\n",
       "      <td>0.776347</td>\n",
       "      <td>1.115150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pc1       pc2       pc3       pc4       pc5       pc6       pc7  \\\n",
       "0 -0.938280 -0.019774 -0.016178 -1.547015  0.320923 -0.122549  0.651331   \n",
       "1  0.760479  0.829974 -0.825928 -0.914624 -0.217050 -0.752348  1.173505   \n",
       "2  0.202428 -1.428618 -0.628125 -0.646743 -0.383793  0.902968  0.186972   \n",
       "3 -0.267417  0.668644 -0.262321 -0.454233  0.151922  1.486881 -0.561270   \n",
       "4 -1.646330 -0.700462 -0.152781  0.696984  1.038738 -2.052524 -0.711680   \n",
       "\n",
       "        pc8       pc9      pc10      pc11  \n",
       "0  0.238001  0.332116 -0.134682 -0.135853  \n",
       "1 -0.570348 -0.056062 -1.416116  0.940763  \n",
       "2 -0.307763 -0.360890  0.209880  0.405470  \n",
       "3 -0.170430 -0.441784 -0.619568 -1.010428  \n",
       "4  0.680242 -0.076988  0.776347  1.115150  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc = pca.fit_transform(x_train_sd) # Principal components\n",
    "df_pc = pd.DataFrame(data = pc, columns = ['pc1','pc2','pc3','pc4','pc5','pc6',\n",
    "                                           'pc7','pc8','pc9','pc10','pc11'])\n",
    "df_pc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform dimension reduction (feature selection) by the principal components we've found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_pc = pca.transform(x_train_sd)\n",
    "x_test_pc = pca.transform(x_test_sd) # The features we're going to put in the logistic regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply logistic regression to `x_test_pc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_pca = LogisticRegression(solver = 'lbfgs')\n",
    "lr_pca.fit(x_train_pc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_pca = lr_pca.predict(x_test_pc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare the predicted results with the original test data, we need a confusion matrix, which is defined as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   <center> Confusion Matrix </center>\n",
    "|           |Observe YES      |Observe No        |\n",
    "|-----------|-----------------|------------------|\n",
    "|Predict YES|True Positive  (TP)|False Positive  (FP)|\n",
    "|Predict  NO|False Negative (FN)|True Negative   (TN)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_result(y_test, y_pred):\n",
    "    y_test = np.array(y_test)\n",
    "    y_pred = np.array(y_pred)\n",
    "    cnt_tp = 0; cnt_fp = 0; cnt_fn = 0; cnt_tn = 0\n",
    "    \n",
    "    for i in range(len(y_test)):\n",
    "        if (y_test[i] == 1 and y_pred[i] == 1):\n",
    "            cnt_tp += 1 \n",
    "        elif (y_test[i] == 0 and y_pred[i] == 1):\n",
    "            cnt_fp += 1 \n",
    "        elif (y_test[i] == 1 and y_pred[i] == 0):\n",
    "            cnt_fn += 1\n",
    "        elif (y_test[i] == 0 and y_pred[i] == 0):\n",
    "            cnt_tn += 1\n",
    "\n",
    "    matrix = np.array([[cnt_tp,cnt_fp],[cnt_fn,cnt_tn]])\n",
    "    accuracy = (cnt_tp+cnt_tn)/(cnt_fp+cnt_fn+cnt_tp+cnt_tn)\n",
    "    print(\"The confusion matrix is\\n\")\n",
    "    print(matrix)\n",
    "    print(\"\\n\")\n",
    "    print(\"The accuracy is\")\n",
    "    return round(accuracy, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction result of PCA model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix is\n",
      "\n",
      "[[ 11   2]\n",
      " [162 923]]\n",
      "\n",
      "\n",
      "The acuracy is\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8506"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_result(y_test, y_pred_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cost function of LASSO:\n",
    "$$\\sum_{i=1}^{n}(Y_{i}\\sum_{j=1}^{p} X_{i,j}\\beta_{j})^2 + \\lambda\\sum_{j=1}^{p}\\mid\\beta_{j}\\mid$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we need to determine the regularization parameter $\\alpha$ for our lasso model. When $\\alpha=0$, the lasso model gives the same coefficients as a linear regression. The higher the $\\alpha$, most of the feature coefficients shrink to 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = np.linspace(0.01,1,100)\n",
    "A = []\n",
    "for k in range(len(c)):\n",
    "    clf = LogisticRegression(penalty=\"l1\", solver='saga', C=c[k])\n",
    "    clf.fit(x_train_sd, y_train)\n",
    "    y_pred_lasso = clf.predict(x_test_sd)\n",
    "    A.append(pred_result(y_test, y_pred_lasso))\n",
    "A.index(max(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, we choose $C=0.16$ for the lasso regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(penalty=\"l1\", solver='saga', C=0.16)\n",
    "clf.fit(x_train_sd, y_train)\n",
    "y_pred_lasso = clf.predict(x_test_sd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take a look at the coefficients of our shrinkage model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.757e-01,  5.555e-01, -3.040e-02,  0.000e+00,  1.981e-01,\n",
       "         0.000e+00,  6.340e-02,  1.172e-01,  0.000e+00,  1.085e-01,\n",
       "         2.875e-01,  0.000e+00, -1.000e-04,  0.000e+00,  1.384e-01]])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(clf.coef_,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable `currentSmoker`, `BPMeds`, `diabetes`, `diaBP`, `heartRate` are shrunk to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction result of the lasso model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix is\n",
      "\n",
      "[[ 12   1]\n",
      " [161 924]]\n",
      "\n",
      "\n",
      "The accuracy is\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8525"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_result(y_test, y_pred_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_elastic = LogisticRegression(penalty=\"elasticnet\", solver='saga', C=0.16)\n",
    "clf_elastic.fit(x_train_sd, y_train)\n",
    "y_pred_elastic = clf_elastic.predict(x_test_sd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take a look at the coefficients of the elastic net model, which do not shrink to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.297 ,  0.5587, -0.0532, -0.0175,  0.222 ,  0.0093,  0.0728,\n",
       "         0.1338, -0.0225,  0.1278,  0.2944, -0.0072, -0.0297,  0.0032,\n",
       "         0.1653]])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(clf_elastic.coef_,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction result of the elastic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix is\n",
      "\n",
      "[[ 11   3]\n",
      " [162 922]]\n",
      "\n",
      "\n",
      "The accuracy is\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8497"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_result(y_test, y_pred_elastic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The elastic net is not a good model for prediction, since its accuracy score is equal to the original logistic regression that does not perform feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(x_train_sd, y_train)\n",
    "y_pred_lr = clf_elastic.predict(x_test_sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix is\n",
      "\n",
      "[[ 11   3]\n",
      " [162 922]]\n",
      "\n",
      "\n",
      "The accuracy is\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8497"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_result(y_test, y_pred_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=2, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=100, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import cluster\n",
    "clf_kmeans = cluster.KMeans(init='k-means++', n_clusters=2, random_state=100)\n",
    "clf_kmeans.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_kmeans = clf_kmeans.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction result of Kmeans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix is\n",
      "\n",
      "[[ 95 395]\n",
      " [ 78 530]]\n",
      "\n",
      "\n",
      "The accuracy is\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5692"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_result(y_test, y_pred_kmeans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support vector machine (SVM) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = svm.SVC(gamma = 0.001, C = 10, kernel='linear')\n",
    "svc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svc = svc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix is\n",
      "\n",
      "[[  9   2]\n",
      " [164 923]]\n",
      "\n",
      "\n",
      "The accuracy is\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8488"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_result(y_test, y_pred_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    " 1. Since we aim to improve the prediction on `TenYearCHD`, we did not perform cross-validaton for searching the $\\alpha$ that resulted in the smallest MSE. \n",
    " 2. Compared to the original logistic regression, PCA and LASSO successfully performs dimension reduction (from 15 to 11) and improves the accuracy of prediction.\n",
    " 3. LASSO performs the best in predicting `TenYearCHD` for our test data. \n",
    " 4. Elastic net model does not perform feature selection, therefore the it results in the same prediction result as the original logistic regression `lr`.\n",
    " 5. It is reasonable that KMeans performs the worst since it does not need target value(`TenYearCHD`) when classifying.\n",
    " 6. SVM is slightly worse than the original logistic regression."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
